#!/bin/bash
#
# (c) Copyright 2019 SUSE LLC
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#
# Run through the Ardana update workflow to update the Cloud
# within the same stream using updated package sources.
#

set -eux
set -o pipefail

cmd_name="$(basename ${BASH_SOURCE[0]})"
cmd_dir="$(dirname "$(readlink -e "${BASH_SOURCE[0]}")")"

eval "$(${cmd_dir}/ardana-env)"

usage() {
    set +x
    echo "${cmd_name} [options] [cloud]"
    echo
    echo "cloud defaults to deployerincloud"
    echo
    echo "--c8, --c8-devel    -- Test DC8 ==> DC8S update."
    echo "--c8-hos            -- Use the HOS flavour of Cloud8; SOC is default."
    echo "--c8-pool           -- Test C8 Pool ==> Updates update."
    echo "--c8-updates        -- Test C8 Pool + Updates ==> Updates-test update."
    echo "--c9, --c9-devel    -- Test DC9 ==> DC9S update. (default)"
    echo "--c9-pool           -- Test C9 Pool ==> Updates update."
    echo "--c9-updates        -- Test C9 Pool + Updates ==> Updates-test update."
    echo "--no-setup          -- Don't run dev-env-install.yml."
    echo "--no-update-rpms    -- Don't build RPMs from local clones."
    echo "--patch             -- Use the zypper patch method."
    echo "--pre-destroy       -- Destroy any existing instance of cloud first."
    echo "--rhel-compute      -- Enable RHEL computes."
    echo "--sles-compute      -- Enable SLES computes (default)."
    echo "--update            -- Use the zypper update method."
}

# Manage list of long options as a sorted array of option names which
# we then join with commas to form the argument to getopt
long_opts=(
    c8
    c8-devel
    c8-hos
    c8-pool
    c8-updates
    c9
    c9-devel
    c9-pool
    c9-updates
    ci
    help
    no-setup
    no-update-rpms
    patch
    pre-destroy
    rhel-compute
    sles-compute
    update
)

# join long_opts members with ","
printf -v OPTIONS ",%s" "${long_opts[@]:1}"
OPTIONS="${long_opts[0]}${OPTIONS}"

TEMP=$(getopt -o -h -l $OPTIONS -n $cmd_name -- "${@}")
if (( $? != 0 ))
then
    echo "Terminating..." >&2
    exit 1
fi

# Note the quotes around `$TEMP': they are essential!
eval set -- "$TEMP"

cloud_version=
pre_destroy=
zypper_method=
common_args=()
cloud_args=()
update_args=()


while true ; do
    case "${1}" in
    (-h|--help)
        usage
        exit 0
        ;;
    (--c8|--c8-*|--c9|--c9-*)
        cloud_version="${1:3:1}"
        case "${1}" in
        (*-devel)
            cloud_args+=( "--c${cloud_version}-devel" )
            update_args+=( "--c${cloud_version}-staging" )
            ;;
        (*-hos)
            if [[ "${cloud_version}" != "8" ]]
            then
                echo "ERROR: There is no HOS variant for Cloud${cloud_version}!"
                exit 1
            fi
            common_args+=( "${1}" )
            ;&
        (*-pool)
            cloud_args+=( "--c${cloud_version}-pool" )
            update_args+=( "--c${cloud_version}-updates" )
            ;;
        (*-updates)
            cloud_args+=( "--c${cloud_version}-updates" )
            update_args+=( "--c${cloud_version}-updates-test" )
            ;;
        esac
        shift
        ;;
    (--rhel-compute|--sles-compute)
        common_args+=( "${1}" )
        shift
        ;;
    (--ci|--no-setup|--no-update-rpms)
        common_args+=( "${1}" )
        shift
        ;;
    (--patch|--update)
        zypper_method="${1:2}"
        shift
        ;;
    (--pre-destroy)
        pre_destroy="${1}"
        shift
        ;;
    (--)
        shift
        break
        ;;
    (*)
        break
        ;;
    esac
done

if [[ -z "${cloud_version}" ]]
then
    cloud_version=9
fi

if [[ -z "${zypper_method}" ]]
then
    zypper_method=update
fi

# Ensure common args has something in it to keep bash checking happy
common_args+=( --c${cloud_version} )

if (( ${#cloud_args[@]} == 0 ))
then
    cloud_args+=( "--c${cloud_version}-devel" )
fi

if (( ${#update_args[@]} == 0 ))
then
    update_args+=( "--c${cloud_version}-staging" )
fi

if [[ -t 1 ]]
then
    ssh_opts="-t"
else
    ssh_opts=
fi

deployer_ssh()
{
    ssh -F ${vagrant_dir}/astack-ssh-config ${ssh_opts} deployer "${@}"
}

deployer_scp()
{
    local dest="${1}"

    shift

    scp -F ${vagrant_dir}/astack-ssh-config "${@}" deployer:"${dest}"
}

ardana_deployer_run_playbook()
{
    local node="${1}" pb="${2}" pd="${3}"

    shift 3

    echo "***** [ Running '${pd}/${pb}' for node '${node}' on deployer ] *****"
    deployer_ssh \
        "cd ${pd} && \
         ansible-playbook ${pb}.yml \
             --limit ${node} \
             ${@}"
}

ardana_openstack_run_playbook()
{
    local node="${1}" pb="${2}"

    shift 2

    ardana_deployer_run_playbook \
        "${node}" \
        "${pb}" \
        "~ardana/openstack/ardana/ansible" \
        "${@}"
}

ardana_scratch_run_playbook()
{
    local node="${1}" pb="${2}"

    shift 2

    ardana_deployer_run_playbook \
        "${node}" \
        "${pb}" \
        "~ardana/scratch/ansible/next/ardana/ansible" \
        "${@}"
}

ardana_scratch_update_status()
{
    local node="${1}"

    shift

    ardana_scratch_run_playbook "${node}" ardana-update-status "${@}"
}

deployer_needs_update()
{
    ardana_scratch_update_status "${1}" 2>&1 | grep "ardana-update.yml"
}

deployer_needs_reboot()
{
    ardana_scratch_update_status "${1}" 2>&1 | grep "ardana-reboot.yml"
}



set -x

cloud_name="${1:-adt}"
vagrant_dir="${cmd_dir}/../ardana-vagrant-models/${cloud_name}-vagrant"
ansible_dir="${cmd_dir}/../ansible"

# Retrieve artifacts for initial cloud and updates runs
${cmd_dir}/astack.sh \
    "${common_args[@]}" \
    "${cloud_args[@]}" \
    ${pre_destroy} \
    --no-update-rpms \
    --no-cloud \
    "${cloud_name}"

# no need to run setup phase again, so skip in future astack invocations
common_args+=( --no-setup )

${cmd_dir}/astack.sh \
    "${common_args[@]}" \
    "${update_args[@]}" \
    --no-update-rpms \
    --no-cloud \
    "${cloud_name}"

# all artifacts have been retrieved so no need to retrieve again
common_args+=( --no-artifacts )

# Force re-creation of the local input-model cache
rm -rf "${vagrant_dir}/input-model"

# Bring up the cloud, using already fetched artifacts, running
# tempest tests to confirm correct operation.
${cmd_dir}/astack.sh \
    "${common_args[@]}" \
    "${cloud_args[@]}" \
    --run-tests \
    "${cloud_name}"

source ${cmd_dir}/libci.sh

pushd "${ansible_dir}"

# disable/remove existing zypper repos
${cmd_dir}/ardana --cloud ${cloud_name} \
    ansible-playbook \
        -i hosts/cloud.yml \
        ${ansible_dir}/cloud-repos-update.yml \
        -e zypper_repo_enabled=no \
        -e zypper_repo_state=absent

# Switch to update cloud settings
${cmd_dir}/astack.sh \
    "${common_args[@]}" \
    "${update_args[@]}" \
    --no-update-rpms \
    --no-cloud \
    "${cloud_name}"

# create/enable new zypper repos
${cmd_dir}/ardana --cloud ${cloud_name} \
    ansible-playbook \
        -i hosts/cloud.yml \
        cloud-repos-update.yml

# Install/Update Cloud pattern packages and run ardana-init, but skip model init
${cmd_dir}/ardana --cloud ${cloud_name} \
    ansible-playbook \
        -i hosts/cloud.yml \
        cloud-deployer-init.yml \
        -e skip_model_init

# config-cloud.sh should already be there but no harm in copying up again
deployer_scp config-cloud.sh ${cmd_dir}/deployer/config-cloud.sh

# run config-cloud.sh to regenerate the scratch area with updated Ardana
# ansible code base.
deployer_ssh ./config-cloud.sh

# run the update-pkgs playbook
ardana_scratch_run_playbook \
    OPS-LM--first-member \
    ardana-update-pkgs \
    -e zypper_update_method=${zypper_method} \
    -e zypper_update_gpg_checks=true \
    -e zypper_update_licenses_agree=true \
    -e zypper_update_include_reboot_patches=true

if deployer_needs_update
then
    ardana_scratch_run_playbook \
        OPS-LM--first-member \
        ardana-update
fi

if deployer_needs_reboot
then
    # this will fail saying deployer node needs to be manually rebooted
    # and that we need to run _ardana-post-reboot.yml after rebooting.
    ardana_scratch_run_playbook \
        OPS-LM--first-member \
        ardana-reboot || true

    # Now "manually" reboot the deployer node
    ${cmd_dir}/ardana --cloud ${cloud_name} \
        ansible-playbook \
            -i hosts/cloud.yml \
            ${ansible_dir}/cloud-deployer-reboot.yml

    # now run the _ardana_post-reboot.yml playbook
    ardana_scratch_run_playbook \
        OPS-LM--first-member \
        _ardana-post-reboot
fi

# copy the update-non-deployer-nodes script to the deployer
deployer_scp update-non-deployer-nodes ${cmd_dir}/deployer/update-non-deployer-nodes

# use update-non-deployer-nodes to update the remaining nodes in the cloud
deployer_ssh ./update-non-deployer-nodes update

# use run-tests.sh to validate cloud is working correctly
deployer_ssh ./run-tests.sh ci ${cloud_name}

# vim:shiftwidth=4:tabstop=4:expandtab
